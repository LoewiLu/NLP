{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11.09s get data package ：）\n",
      "X & y prepared\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from time import time\n",
    "from feature_extraction import __get\n",
    "\n",
    "path = r'/Users/loewi/Documents/Pre_Learn/classification/20news-bydate/'\n",
    "os.chdir(path)\n",
    "#print(os.getcwd())\n",
    "\n",
    "t0 = time() \n",
    "\n",
    "newsgroups_train = __get('20news-bydate-train')\n",
    "newsgroups_test = __get('20news-bydate-test')\n",
    "\n",
    "duration = time() - t0\n",
    "print('%0.2fs get data package ：）'%duration)\n",
    "\n",
    "X_train, X_test = newsgroups_train['data'], newsgroups_test['data']\n",
    "y_train, y_test = newsgroups_train['docs'], newsgroups_test['docs']\n",
    "print('X & y prepared')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer,TfidfVectorizer,HashingVectorizer,TfidfTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import cross_val_score,StratifiedKFold,GridSearchCV,RandomizedSearchCV\n",
    "from pprint import pprint\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy:   0.505\n"
     ]
    }
   ],
   "source": [
    "vectorizer = HashingVectorizer(stop_words='english')\n",
    "X = vectorizer.fit_transform( X_train )\n",
    "Xt= vectorizer.transform( X_test )\n",
    "clf = RandomForestClassifier()\n",
    "clf.fit(X, y_train)\n",
    "#RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
    "#            max_depth=2, max_features='auto', max_leaf_nodes=None,\n",
    "#            min_impurity_decrease=0.0, min_impurity_split=None,\n",
    "#            min_samples_leaf=1, min_samples_split=2,\n",
    "#            min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=None,\n",
    "#            oob_score=False, random_state=0, verbose=0, warm_start=False)\n",
    "#print(clf.feature_importances_)\n",
    "\n",
    "pred = clf.predict(Xt)\n",
    "score = metrics.accuracy_score(y_test, pred)\n",
    "print(\"accuracy:   %0.3f\" % score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing randomized search...\n",
      "pipeline: ['vect', 'clf']\n",
      "parameters:\n",
      "{'clf__n_estimators': range(10, 201, 10)}\n",
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed: 84.3min\n",
      "[Parallel(n_jobs=-1)]: Done  50 out of  50 | elapsed: 113.1min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 7912.154s\n",
      "\n",
      "Best score: 0.782\n",
      "Best parameters set:\n",
      "\tclf__n_estimators: 180\n"
     ]
    }
   ],
   "source": [
    "pipeline = Pipeline([\n",
    "                ('vect', HashingVectorizer(\n",
    "                        lowercase = True,\n",
    "                        stop_words= 'english',\n",
    "                        token_pattern= r'(?u)\\b[a-zA-Z_][a-zA-Z_]+\\b'\n",
    "                        )),\n",
    "                \n",
    "                ('clf', RandomForestClassifier()),\n",
    "                ])\n",
    "parameters = {\n",
    "          #  'vect__ngram_range':((1, 1), (1, 2)), \n",
    "            'clf__n_estimators': range(10,201,10), #弱学习器迭代次数\n",
    "}    \n",
    "#n_iter_search = 20\n",
    "#cv = StratifiedKFold(n_splits= 5 ,random_state=0,shuffle=True)\n",
    "clf = RandomizedSearchCV(pipeline, parameters,n_jobs=-1, verbose=1, cv = 5)\n",
    "print(\"Performing randomized search...\")\n",
    "print(\"pipeline:\", [name for name, _ in pipeline.steps])\n",
    "print(\"parameters:\")\n",
    "pprint(parameters)\n",
    "t0 = time()\n",
    "clf.fit(X_train, y_train)\n",
    "print(\"done in %0.3fs\" % (time() - t0))\n",
    "print()\n",
    "\n",
    "print(\"Best score: %0.3f\" % clf.best_score_)\n",
    "print(\"Best parameters set:\")\n",
    "best_parameters = clf.best_estimator_.get_params()\n",
    "for param_name in sorted(parameters.keys()):\n",
    "    print(\"\\t%s: %r\" % (param_name, best_parameters[param_name]))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing grid search...\n",
      "pipeline: ['vect', 'clf']\n",
      "parameters:\n",
      "{'clf__max_depth': range(80, 101, 10),\n",
      " 'clf__min_samples_split': range(110, 151, 10),\n",
      " 'clf__n_estimators': range(190, 201, 10)}\n",
      "Fitting 5 folds for each of 30 candidates, totalling 150 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:  3.4min\n",
      "[Parallel(n_jobs=-1)]: Done 150 out of 150 | elapsed: 13.7min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 852.781s\n",
      "\n",
      "Best score: 0.743\n",
      "Best parameters set:\n",
      "\tclf__max_depth: 100\n",
      "\tclf__min_samples_split: 110\n",
      "\tclf__n_estimators: 190\n"
     ]
    }
   ],
   "source": [
    "pipeline = Pipeline([\n",
    "                ('vect', HashingVectorizer(\n",
    "                        lowercase = True,\n",
    "                        stop_words= 'english',\n",
    "                        token_pattern= r'(?u)\\b[a-zA-Z_][a-zA-Z_]+\\b',\n",
    "                        )),\n",
    "                \n",
    "                ('clf', RandomForestClassifier(\n",
    "                        \n",
    "                )),\n",
    "                ])\n",
    "parameters = {\n",
    "            'clf__n_estimators': range(150,201,10),\n",
    "            'clf__max_depth':range(80,101,10),\n",
    "            'clf__min_samples_split':range(110,151,10), \n",
    "\n",
    "}    \n",
    "#n_iter_search = 20\n",
    "cv = StratifiedKFold(n_splits= 5 ,random_state=0,shuffle=True)\n",
    "clf = GridSearchCV(pipeline, parameters,n_jobs=-1, verbose=1, cv = cv)\n",
    "print(\"Performing grid search...\")\n",
    "print(\"pipeline:\", [name for name, _ in pipeline.steps])\n",
    "print(\"parameters:\")\n",
    "pprint(parameters)\n",
    "t0 = time()\n",
    "clf.fit(X_train, y_train)\n",
    "print(\"done in %0.3fs\" % (time() - t0))\n",
    "print()\n",
    "\n",
    "print(\"Best score: %0.3f\" % clf.best_score_)\n",
    "print(\"Best parameters set:\")\n",
    "best_parameters = clf.best_estimator_.get_params()\n",
    "for param_name in sorted(parameters.keys()):\n",
    "    print(\"\\t%s: %r\" % (param_name, best_parameters[param_name]))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing grid search...\n",
      "pipeline: ['vect', 'clf']\n",
      "parameters:\n",
      "{'clf__min_samples_leaf': range(10, 101, 10),\n",
      " 'clf__min_samples_split': range(10, 201, 10)}\n",
      "Fitting 5 folds for each of 200 candidates, totalling 1000 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:  1.8min\n",
      "[Parallel(n_jobs=-1)]: Done 184 tasks      | elapsed:  6.9min\n",
      "[Parallel(n_jobs=-1)]: Done 434 tasks      | elapsed: 13.4min\n",
      "[Parallel(n_jobs=-1)]: Done 784 tasks      | elapsed: 21.7min\n",
      "[Parallel(n_jobs=-1)]: Done 1000 out of 1000 | elapsed: 26.7min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 1612.833s\n",
      "\n",
      "Best score: 0.698\n",
      "Best parameters set:\n",
      "\tclf__min_samples_leaf: 10\n",
      "\tclf__min_samples_split: 160\n"
     ]
    }
   ],
   "source": [
    "pipeline = Pipeline([\n",
    "                ('vect', HashingVectorizer(\n",
    "                        lowercase = True,\n",
    "                        stop_words= 'english',\n",
    "                        token_pattern= r'(?u)\\b[a-zA-Z_][a-zA-Z_]+\\b',\n",
    "                        )),\n",
    "                \n",
    "                ('clf', RandomForestClassifier(\n",
    "                        n_estimators = 190,\n",
    "                        max_depth = 100,\n",
    "                    \n",
    "                )),\n",
    "                ])\n",
    "#内部节点再划分\n",
    "parameters = {\n",
    "            'clf__min_samples_split':range(10,201,10),\n",
    "            'clf__min_samples_leaf':range(10,101,10)\n",
    "\n",
    "}    \n",
    "#n_iter_search = 100\n",
    "cv = StratifiedKFold(n_splits= 5 ,random_state=0,shuffle=True)\n",
    "clf = GridSearchCV(pipeline, parameters,n_jobs=-1, verbose=1, cv = cv)\n",
    "print(\"Performing grid search...\")\n",
    "print(\"pipeline:\", [name for name, _ in pipeline.steps])\n",
    "print(\"parameters:\")\n",
    "pprint(parameters)\n",
    "t0 = time()\n",
    "clf.fit(X_train, y_train)\n",
    "print(\"done in %0.3fs\" % (time() - t0))\n",
    "print()\n",
    "\n",
    "print(\"Best score: %0.3f\" % clf.best_score_)\n",
    "print(\"Best parameters set:\")\n",
    "best_parameters = clf.best_estimator_.get_params()\n",
    "for param_name in sorted(parameters.keys()):\n",
    "    print(\"\\t%s: %r\" % (param_name, best_parameters[param_name]))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing grid search...\n",
      "pipeline: ['vect', 'clf']\n",
      "parameters:\n",
      "{'clf__max_depth': range(2, 202, 10)}\n",
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:  1.4min\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:  3.9min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 246.508s\n",
      "\n",
      "Best score: 0.697\n",
      "Best parameters set:\n",
      "\tclf__max_depth: 152\n"
     ]
    }
   ],
   "source": [
    "pipeline = Pipeline([\n",
    "                ('vect', HashingVectorizer(\n",
    "                        lowercase = True,\n",
    "                        stop_words= 'english',\n",
    "                        token_pattern= r'(?u)\\b[a-zA-Z_][a-zA-Z_]+\\b',\n",
    "                        )),\n",
    "                \n",
    "                ('clf', RandomForestClassifier(\n",
    "                        n_estimators = 180,                        \n",
    "                        min_samples_split = 160,\n",
    "                        min_samples_leaf = 10\n",
    "                )),\n",
    "                ])\n",
    "#内部节点再划分\n",
    "parameters = {\n",
    "            'clf__max_depth':range(2,202,10),\n",
    "            \n",
    "\n",
    "}    \n",
    "#n_iter_search = 100\n",
    "cv = StratifiedKFold(n_splits= 5 ,random_state=0,shuffle=True)\n",
    "clf = GridSearchCV(pipeline, parameters,n_jobs=-1, verbose=1, cv = cv)\n",
    "print(\"Performing grid search...\")\n",
    "print(\"pipeline:\", [name for name, _ in pipeline.steps])\n",
    "print(\"parameters:\")\n",
    "pprint(parameters)\n",
    "t0 = time()\n",
    "clf.fit(X_train, y_train)\n",
    "print(\"done in %0.3fs\" % (time() - t0))\n",
    "print()\n",
    "\n",
    "print(\"Best score: %0.3f\" % clf.best_score_)\n",
    "print(\"Best parameters set:\")\n",
    "best_parameters = clf.best_estimator_.get_params()\n",
    "for param_name in sorted(parameters.keys()):\n",
    "    print(\"\\t%s: %r\" % (param_name, best_parameters[param_name]))    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing randomized search...\n",
      "pipeline: ['vect', 'clf']\n",
      "parameters:\n",
      "{'clf__max_depth': range(2, 502, 20),\n",
      " 'clf__min_samples_leaf': range(1, 101, 10),\n",
      " 'clf__min_samples_split': range(2, 501, 20)}\n",
      "Fitting 5 folds for each of 500 candidates, totalling 2500 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:  3.6min\n",
      "[Parallel(n_jobs=-1)]: Done 184 tasks      | elapsed: 11.7min\n",
      "[Parallel(n_jobs=-1)]: Done 434 tasks      | elapsed: 23.1min\n",
      "[Parallel(n_jobs=-1)]: Done 784 tasks      | elapsed: 60.5min\n",
      "[Parallel(n_jobs=-1)]: Done 1234 tasks      | elapsed: 79.2min\n",
      "[Parallel(n_jobs=-1)]: Done 1784 tasks      | elapsed: 102.0min\n",
      "[Parallel(n_jobs=-1)]: Done 2434 tasks      | elapsed: 134.4min\n",
      "[Parallel(n_jobs=-1)]: Done 2500 out of 2500 | elapsed: 136.6min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 9124.378s\n",
      "\n",
      "Best score: 0.788\n",
      "Best parameters set:\n",
      "\tclf__max_depth: 422\n",
      "\tclf__min_samples_leaf: 1\n",
      "\tclf__min_samples_split: 2\n"
     ]
    }
   ],
   "source": [
    "pipeline = Pipeline([\n",
    "                ('vect', HashingVectorizer(\n",
    "                        lowercase = True,\n",
    "                        stop_words= 'english',\n",
    "                        token_pattern= r'(?u)\\b[a-zA-Z_][a-zA-Z_]+\\b',\n",
    "                        )),\n",
    "                \n",
    "                ('clf', RandomForestClassifier(\n",
    "                        n_estimators = 180,\n",
    "                )),\n",
    "                ])\n",
    "parameters = {\n",
    "            'clf__max_depth':range(2,502,20),#决策树最大深度\n",
    "            'clf__min_samples_split':range(2,501,20),#内部节点再划分所需最小样本数\n",
    "            'clf__min_samples_leaf': range(1, 101, 10),\n",
    "}    \n",
    "# bootstrap=True, class_weight=None, criterion='gini',\n",
    "#            max_depth=2, max_features='auto', max_leaf_nodes=None,\n",
    "#            min_impurity_decrease=0.0, min_impurity_split=None,\n",
    "#            min_samples_leaf=1, min_samples_split=2,\n",
    "#            min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=None,\n",
    "#            oob_score=False, random_state=0, verbose=0, warm_start=False\n",
    "\n",
    "n_iter_search = 500\n",
    "cv = StratifiedKFold(n_splits= 5 ,random_state=0,shuffle=True)\n",
    "clf = RandomizedSearchCV(pipeline, parameters, n_jobs=-1, verbose=1, cv = cv, n_iter = n_iter_search)\n",
    "print(\"Performing randomized search...\")\n",
    "print(\"pipeline:\", [name for name, _ in pipeline.steps])\n",
    "print(\"parameters:\")\n",
    "pprint(parameters)\n",
    "t0 = time()\n",
    "clf.fit(X_train, y_train)\n",
    "print(\"done in %0.3fs\" % (time() - t0))\n",
    "print()\n",
    "\n",
    "print(\"Best score: %0.3f\" % clf.best_score_)\n",
    "print(\"Best parameters set:\")\n",
    "best_parameters = clf.best_estimator_.get_params()\n",
    "for param_name in sorted(parameters.keys()):\n",
    "    print(\"\\t%s: %r\" % (param_name, best_parameters[param_name]))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model with rank: 1\n",
      "Mean validation score: 0.788 (std: 0.008)\n",
      "Parameters: {'clf__min_samples_split': 2, 'clf__min_samples_leaf': 1, 'clf__max_depth': 422}\n",
      "\n",
      "Model with rank: 2\n",
      "Mean validation score: 0.783 (std: 0.008)\n",
      "Parameters: {'clf__min_samples_split': 2, 'clf__min_samples_leaf': 1, 'clf__max_depth': 162}\n",
      "\n",
      "Model with rank: 3\n",
      "Mean validation score: 0.781 (std: 0.007)\n",
      "Parameters: {'clf__min_samples_split': 2, 'clf__min_samples_leaf': 1, 'clf__max_depth': 142}\n",
      "\n",
      "Model with rank: 4\n",
      "Mean validation score: 0.778 (std: 0.005)\n",
      "Parameters: {'clf__min_samples_split': 22, 'clf__min_samples_leaf': 1, 'clf__max_depth': 202}\n",
      "\n",
      "Model with rank: 5\n",
      "Mean validation score: 0.772 (std: 0.006)\n",
      "Parameters: {'clf__min_samples_split': 22, 'clf__min_samples_leaf': 1, 'clf__max_depth': 142}\n",
      "\n",
      "Model with rank: 6\n",
      "Mean validation score: 0.772 (std: 0.006)\n",
      "Parameters: {'clf__min_samples_split': 42, 'clf__min_samples_leaf': 1, 'clf__max_depth': 202}\n",
      "\n",
      "Model with rank: 7\n",
      "Mean validation score: 0.766 (std: 0.010)\n",
      "Parameters: {'clf__min_samples_split': 82, 'clf__min_samples_leaf': 1, 'clf__max_depth': 482}\n",
      "\n",
      "Model with rank: 8\n",
      "Mean validation score: 0.765 (std: 0.006)\n",
      "Parameters: {'clf__min_samples_split': 82, 'clf__min_samples_leaf': 1, 'clf__max_depth': 362}\n",
      "\n",
      "Model with rank: 9\n",
      "Mean validation score: 0.764 (std: 0.012)\n",
      "Parameters: {'clf__min_samples_split': 82, 'clf__min_samples_leaf': 1, 'clf__max_depth': 342}\n",
      "\n",
      "Model with rank: 10\n",
      "Mean validation score: 0.762 (std: 0.006)\n",
      "Parameters: {'clf__min_samples_split': 82, 'clf__min_samples_leaf': 1, 'clf__max_depth': 262}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "def report(results, n_top=10):\n",
    "    for i in range(1, n_top + 1):\n",
    "        candidates = np.flatnonzero(results['rank_test_score'] == i)\n",
    "        for candidate in candidates:\n",
    "            print(\"Model with rank: {0}\".format(i))\n",
    "            print(\"Mean validation score: {0:.3f} (std: {1:.3f})\".format(\n",
    "                  results['mean_test_score'][candidate],\n",
    "                  results['std_test_score'][candidate]))\n",
    "            print(\"Parameters: {0}\".format(results['params'][candidate]))\n",
    "            print(\"\")\n",
    "            \n",
    "report(clf.cv_results_)           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing randomized search...\n",
      "pipeline: ['vect', 'clf']\n",
      "parameters:\n",
      "{'clf__max_depth': range(150, 502, 10),\n",
      " 'clf__max_features': ('sqrt', 0.8),\n",
      " 'clf__min_samples_leaf': range(10, 101, 10),\n",
      " 'clf__min_samples_split': range(2, 101, 10)}\n",
      "Fitting 5 folds for each of 100 candidates, totalling 500 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed: 124.4min\n",
      "[Parallel(n_jobs=-1)]: Done 184 tasks      | elapsed: 562.2min\n"
     ]
    }
   ],
   "source": [
    "pipeline = Pipeline([\n",
    "                ('vect', HashingVectorizer(\n",
    "                        lowercase = True,\n",
    "                        stop_words= 'english',\n",
    "                        token_pattern= r'(?u)\\b[a-zA-Z_][a-zA-Z_]+\\b',\n",
    "                        )),\n",
    "                \n",
    "                ('clf', RandomForestClassifier(\n",
    "                        n_estimators = 180,\n",
    "                    \n",
    "                )),\n",
    "                ])\n",
    "parameters = {\n",
    "            'clf__max_depth':range(150,502,10),#决策树最大深度\n",
    "            'clf__min_samples_split':range(2,101,10),#内部节点再划分所需最小样本数\n",
    "            'clf__max_features':('sqrt', 0.8),#划分时考虑的最大特征数\n",
    "            'clf__min_samples_leaf': range(10,101,10),#限制叶子节点最少的样本数;叶子节点数目小于样本数，会和兄弟节点一起被剪枝\n",
    "            \n",
    "}    \n",
    "# bootstrap=True, class_weight=None, criterion='gini',\n",
    "#            max_depth=2, max_features='auto', max_leaf_nodes=None,\n",
    "#            min_impurity_decrease=0.0, min_impurity_split=None,\n",
    "#            min_samples_leaf=1, min_samples_split=2,\n",
    "#            min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=None,\n",
    "#            oob_score=False, random_state=0, verbose=0, warm_start=False\n",
    "\n",
    "n_iter_search = 100\n",
    "cv = StratifiedKFold(n_splits= 5 ,random_state=0,shuffle=True)\n",
    "clf = RandomizedSearchCV(pipeline, parameters, n_jobs=-1, verbose=1, cv = cv, n_iter = n_iter_search)\n",
    "print(\"Performing randomized search...\")\n",
    "print(\"pipeline:\", [name for name, _ in pipeline.steps])\n",
    "print(\"parameters:\")\n",
    "pprint(parameters)\n",
    "t0 = time()\n",
    "clf.fit(X_train, y_train)\n",
    "print(\"done in %0.3fs\" % (time() - t0))\n",
    "print()\n",
    "\n",
    "print(\"Best score: %0.3f\" % clf.best_score_)\n",
    "print(\"Best parameters set:\")\n",
    "best_parameters = clf.best_estimator_.get_params()\n",
    "for param_name in sorted(parameters.keys()):\n",
    "    print(\"\\t%s: %r\" % (param_name, best_parameters[param_name]))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.64477743 0.64872021 0.66961131 0.6659292  0.65631929]\n",
      "training accuracy: 0.657 (+/- 0.019)\n",
      "testing accuracy:   0.616\n"
     ]
    }
   ],
   "source": [
    "#%% predict\n",
    "    \n",
    "from sklearn import metrics  \n",
    "clf_validated = Pipeline([\n",
    "                ('vect', HashingVectorizer(\n",
    "                        lowercase = True,\n",
    "                        stop_words= 'english',\n",
    "                        token_pattern= r'(?u)\\b[a-zA-Z_][a-zA-Z_]+\\b',\n",
    "                        )),\n",
    "                \n",
    "                ('clf', RandomForestClassifier(\n",
    "                        n_estimators = 180,\n",
    "                        min_samples_split = 22,\n",
    "                        max_depth = 202,\n",
    "                ))\n",
    "])\n",
    "                \n",
    "clf_validated.fit(X_train, y_train)  \n",
    "cv = StratifiedKFold(n_splits= 5 ,random_state=0,shuffle=True)\n",
    "scores = cross_val_score(clf_validated, X_train, y_train,  cv = cv, scoring='accuracy')\n",
    "print (scores)\n",
    "score = scores.mean()\n",
    "print(\"training accuracy: %0.3f (+/- %0.3f)\" % (score, scores.std() * 2))\n",
    "              \n",
    "pred = clf_validated.predict(X_test)\n",
    "score = metrics.accuracy_score(y_test, pred)\n",
    "print(\"testing accuracy:   %0.3f\" % score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
    "#            max_depth=2, max_features='auto', max_leaf_nodes=None,\n",
    "#            min_impurity_decrease=0.0, min_impurity_split=None,\n",
    "#            min_samples_leaf=1, min_samples_split=2,\n",
    "#            min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=None,\n",
    "#            oob_score=False, random_state=0, verbose=0, warm_start=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
